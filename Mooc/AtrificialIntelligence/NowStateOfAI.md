# The State of The Art

### Categories

|              |     Humanly      |     Rationally      |
| :----------: | :--------------: | :-----------------: |
|  **Acting**  |  Acting humanly  |  Acting rationally  |
| **Thinking** | Thinking humanly | Thinking rationally |

Humanly

-to measure success of terms of fidelity to human performance. ~模仿人类表现逼真程度~

Rationally

-to measure against an ideal performance measure. ~系统对于已知的知识做出正确的动作,称为理性~



Acting humanly ~active~

-to make computers **do** ~active~ the things at which , at the moment , people are better.

Acting rationally ~intelligence\ behavior~

-how to design intelligent agents.



Thinking humanly ~minds~

-human thinking automation.

Thinking rationally ~perceive~

-to make computer possible to perceive,reason,and act

---

### Weak AI ~now\ state~

-Artificial Narrow Intelligence(ANI) ~人工狭义智能~

-non-Sentient

-focused On **narrow** task (special problem)

### Strong AI ~primary\ goal~

-Artificial General Intelligence(AGI) ~人工广义智能~

-a machine with the ability to apply intelligence to **any** problem

### Super AI

-Artificial Super Intelligence(ASI) ~人工超级智能~

-a **hypothetical** intelligent that far surpassing that of the brightest that human.

---

### Other Fields in Which AI is implements

Artificial life, Automated reasoning, Automation, Data mining, Semantic Web,....

---

Related papers:

"A Global Geometric Framework for Nonlinear Dimensionality Reduction"

“一种用于非线性降维的全局几何框架”

Author:Joshua Tenenbaum, Vin Silva, John Langford.

SCIENCE ,Vol.290, Dec 2000

summery:

```reStructuredText
“Here we describe an approach to solving dimensionality reduction problems that uses easily measured local metric information to learn the underlying global geometry of a data set.”
“我们在此描述一种解决降维问题的方法,使用易测的局部度量信息来学习数据集潜在的全局几何结构。”
```



“Nonlinear Dimensionality Reduction by Locally Linear Embedding”.

“通过局部线性嵌入进行非线性降维”

Author : Sam Roweis and Lawrence Saul.

SCIENCE, Vol. 290, Dec. 2000.
summery:

```
“Here, we introduce locally linear embedding (LLE),an unsupervised learning algorithm that computes low-dimensional, neighborhood-preserving embeddings of high-dimensional inputs.”
“这里,我们提出局部线性嵌入(LLE),一种计算高维输入数据中低维、邻域保护嵌入的非监督学习算法。”
```



“Reducing the Dimensionality of Data with Neural Networks”.

“利用神经元网络降低数据的维度”

Geoffrey Hinton and Ruslan Salakhutdinov.

SCIENCE, Vol. 313, Jul. 2006.

```
“We describe an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data.”
“我们描述一种初始化权重的有效方法,可让深度自编码网络学习低维代码,作为一种降低数据维度的工具,远远好于主成分分析方法。”
```



“Clustering by fast search and find of density peaks”.

“通过快速查找和发现密度峰值进行聚类”

Alex Rodriguez and Alessandro Laio.

SCIENCE, Vol. 344, Jun. 2014.

```
“We propose an approach based on the idea that cluster centers are characterized by a higher
density than their neighbors and by a relatively large distance from points with higher densities.”
“我们提出一种基于如下思想的方法:聚类中心点具有密度高于相邻点、距离相对大于次高密度点的特性。”
```



“Human-level concept learning through probabilistic program induction”.

“凭借概率规划归纳法进行人类层级的概念学习”

Brenden Lake, Ruslan Salakhutdinov, Joshua Tenenbaum.

SCIENCE, Vol. 350, Dec. 2015.

```
“We see the one-shot learning capacities studied here as a challenge for these neural models: one we expect they might rise to by incorporating the principles of compositionality, causality, and learning to learn that BPL instantiates.”
“我们看到本文研究的一次性学习能力作为对那些神经模型的一种挑战:通过将组合性、因果性和学会学习BPL实例化的原则相结合,成为一个我们期待它们会崛起的方向。”
```



“Human-level control through deep reinforcement learning”.

“凭借深度强化学习达到人类水平的操控”

Volodymyr Mnih, Koray Kavukcuoglu, David Silver, et al.

NATURE, Vol. 518, Feb. 2015.

```
“Here we use recent advances in training deep neural networks to develop a novel artificial agent, termed a deep Q-network, that can learn successful policies directly from high-dimensional sensory inputs using end-to-end reinforcement learning.”
“这里我们采用训练深度网络的最新进展开发一种新颖的人造智能体,称为深度Q网络,应用端到端的强化学习,能直接从高维感知输入中学习成功的策略。”
```



“Deep learning”. 

“深度学习”

Y. LeCun, Y. Bengio and G. Hinton.

NATURE, Vol. 521, May. 2015.

```
“Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. ”
“深度学习通过利用反向传播算法发现大型数据集中复杂的结构表明,一台机器如何改变其内部参数被用于从前一层表征中计算出每层的表征。”
```



“Mastering the game of Go with deep neural networks and tree search”.

“利用深度神经网络和树搜索征服围棋游戏”

David Silver, Aja Huang, Chris Maddison, et al.

NATURE, Vol. 529, Jan. 2016.

```
Here we introduce a new approach to computer Go that uses ‘value networks’ to evaluate board positions and ‘policy networks’ to select moves. ... Without any look ahead search, the neural networks play Go at the level of state-of-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play.
“我们在此提出一种计算机围棋的新方法,使用‘价值网络’评价棋盘位置、使用‘策略网络’选择走子。... 没有任何前向搜索,该神经网络以先进水平的蒙特卡洛树搜索程序博弈围棋,模拟成千上万次随机自我对弈。”
```

